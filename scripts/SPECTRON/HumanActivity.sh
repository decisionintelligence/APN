#!/bin/bash

# --- GPUå¹¶è¡Œè®¾ç½® ---
NUM_GPUS=8
job_count=0

# --- å›ºå®šå‚æ•° ---
model_name="$(basename "$(dirname "$(readlink -f "$0")")")"
dataset_root_path=storage/datasets/HumanActivity
dataset_name=$(basename "$0" .sh)
seq_len=3000
enc_in=12
dec_in=12
c_out=12
pred_len=1000

d_models=(32 64)             # å›ºå®šè¡¨ç°æœ€ä½³çš„ d_model
batch_sizes=(4 8)       # æ ¸å¿ƒæœç´¢å˜é‡: Batch Size
lrs=(0.001)           # æ ¸å¿ƒæœç´¢å˜é‡: Learning Rate
num_kernels=(32 64)          # æ¨¡å‹æ ¸å¿ƒå‚æ•°
num_intra_layers=(3 4)     # æ¨¡å‹æ ¸å¿ƒå‚æ•°
dropouts=(0.1 0.2 0.3)           # æ­£åˆ™åŒ–å‚æ•°
n_heads_list=(2 4)               # æ–°å¢ï¼šæšä¸¾ head ä¸ªæ•°

total_combinations=$(( ${#d_models[@]} * ${#batch_sizes[@]} * ${#lrs[@]} * ${#num_kernels[@]} * ${#num_intra_layers[@]} * ${#dropouts[@]} * ${#n_heads_list[@]} ))
echo "ğŸš€ å¼€å§‹ç»¼åˆç²¾è°ƒæœç´¢ï¼Œæ€»å…±å°†è¿è¡Œ ${total_combinations} ç»„å®éªŒ..."

# --- è®­ç»ƒå¾ªç¯ ---
for dm in "${d_models[@]}"; do
  for bs in "${batch_sizes[@]}"; do
    for lr in "${lrs[@]}"; do
      for nk in "${num_kernels[@]}"; do
        for nil in "${num_intra_layers[@]}"; do
          for dp in "${dropouts[@]}"; do
            for nh in "${n_heads_list[@]}"; do

              gpu_id=$((job_count % NUM_GPUS))

              # æ„å»ºåŒ…å« batch_size å’Œ n_heads çš„å”¯ä¸€ model_id
              model_id="${model_name}_${dataset_name}_sl${seq_len}_pl${pred_len}_dm${dm}_nh${nh}_nk${nk}_nil${nil}_dp${dp}_lr${lr}_bs${bs}"

              echo "----------------------------------------------------"
              echo "ğŸ“ˆ å¯åŠ¨ä»»åŠ¡ [${job_count}] -> GPU ${gpu_id}"
              echo "   Config: bs=${bs}, lr=${lr}, d_model=${dm}, n_heads=${nh}, kernels=${nk}, intra_layers=${nil}, dropout=${dp}"
              echo "   Model ID: ${model_id}"
              echo "----------------------------------------------------"

              # åœ¨åå°å¯åŠ¨è®­ç»ƒä»»åŠ¡ï¼Œå¹¶ä¼ å…¥ batch_size å’Œ n_heads å‚æ•°
              CUDA_VISIBLE_DEVICES=${gpu_id} python main.py \
                --is_training 1 \
                --model_id "$model_id" \
                --model_name "$model_name" \
                --d_model "$dm" \
                --n_heads "$nh" \
                --dropout "$dp" \
                --spectron_num_kernels "$nk" \
                --spectron_d_max 5.0 \
                --spectron_num_intra_layers "$nil" \
                --dataset_root_path "$dataset_root_path" \
                --dataset_name "$dataset_name" \
                --features M \
                --seq_len "$seq_len" \
                --pred_len "$pred_len" \
                --enc_in "$enc_in" \
                --dec_in "$dec_in" \
                --c_out "$c_out" \
                --loss "MSE" \
                --train_epochs 300 \
                --patience 10 \
                --val_interval 1 \
                --itr 5 \
                --batch_size "$bs" \
                --learning_rate "$lr" \
                --use_multi_gpu 0 &

              job_count=$((job_count + 1))
              sleep 2

              if [[ $(jobs -r -p | wc -l) -ge $NUM_GPUS ]]; then
                  wait -n
              fi
            done
          done
        done
      done
    done
  done
done

echo "âœ… æ‰€æœ‰ä»»åŠ¡å·²å¯åŠ¨ï¼Œç­‰å¾…æœ€åæ‰¹æ¬¡çš„ä»»åŠ¡æ‰§è¡Œå®Œæ¯•..."
wait
echo "ğŸ‰ğŸ‰ğŸ‰ å…¨éƒ¨è¶…å‚æ•°æœç´¢ä»»åŠ¡å·²å®Œæˆï¼ğŸ‰ğŸ‰ğŸ‰"